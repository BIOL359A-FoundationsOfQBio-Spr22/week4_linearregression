{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359A  | Simple and Multiple Linear Regression\n",
    "### Spring 2022, Week 4\n",
    "<hr>\n",
    "\n",
    "Objectives:\n",
    "-  Run and interpret a linear regression\n",
    "-  Gain intuition about MLR results\n",
    "-  Introduce concepts like overfitting and test-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/BIOL359A-FoundationsOfQBio-Spr22/week4_linearregression\n",
    "!mkdir ./data\n",
    "!cp week4_linearregression/data/* ./data\n",
    "!cp week4_linearregression/clean_data.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "TITLE_FONT = 20\n",
    "LABEL_FONT = 16\n",
    "TICK_FONT = 16\n",
    "FIG_SIZE = (12,12)\n",
    "COLORS= [\"#008080\",\"#CA562C\"]\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"whitegrid\",  {'axes.linewidth': 2, 'axes.edgecolor':'black'})\n",
    "sns.set(font_scale=1, rc={'figure.figsize':FIG_SIZE}) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to use the Wisconsin Diagnostic Breast Cancer dataset once again\n",
    "\n",
    "From the data source: Wisconsin Diagnostic Breast Cancer (WDBC)\n",
    "\n",
    "```\n",
    "\tFeatures are computed from a digitized image of a fine needle\n",
    "\taspirate (FNA) of a breast mass.  They describe\n",
    "\tcharacteristics of the cell nuclei present in the image.\n",
    "\tA few of the images can be found at\n",
    "\thttp://www.cs.wisc.edu/~street/images/\n",
    "\n",
    "\tSeparating plane described above was obtained using\n",
    "\tMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
    "\tConstruction Via Linear Programming.\" Proceedings of the 4th\n",
    "\tMidwest Artificial Intelligence and Cognitive Science Society,\n",
    "\tpp. 97-101, 1992], a classification method which uses linear\n",
    "\tprogramming to construct a decision tree.  Relevant features\n",
    "\twere selected using an exhaustive search in the space of 1-4\n",
    "\tfeatures and 1-3 separating planes.\n",
    "\n",
    "\tThe actual linear program used to obtain the separating plane\n",
    "\tin the 3-dimensional space is that described in:\n",
    "\t[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
    "\tProgramming Discrimination of Two Linearly Inseparable Sets\",\n",
    "\tOptimization Methods and Software 1, 1992, 23-34].\n",
    "    \n",
    "    Source:\n",
    "    W.N. Street, W.H. Wolberg and O.L. Mangasarian \n",
    "\tNuclear feature extraction for breast tumor diagnosis.\n",
    "\tIS&T/SPIE 1993 International Symposium on Electronic Imaging: Science\n",
    "\tand Technology, volume 1905, pages 861-870, San Jose, CA, 1993.\n",
    "```\n",
    "\n",
    "What do all the column names mean?\n",
    "\n",
    "- ID number\n",
    "- Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "- radius (mean of distances from center to points on the perimeter)\n",
    "- texture (standard deviation of gray-scale values)\n",
    "- perimeter\n",
    "- area\n",
    "- smoothness (local variation in radius lengths)\n",
    "- compactness (perimeter^2 / area - 1.0)\n",
    "- concavity (severity of concave portions of the contour)\n",
    "- concave points (number of concave portions of the contour)\n",
    "- symmetry \n",
    "- fractal dimension (\"coastline approximation\" - 1) - a measure of \"complexity\" of a 2D image.\n",
    "\n",
    "\n",
    "Cateogory Distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Characteristics of our dataset\n",
    "\n",
    "Answer some questions about the structure of our data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  mean_radius  mean_texture  mean_perimeter  mean_area  \\\n",
       "0           M        17.99         10.38          122.80     1001.0   \n",
       "1           M        20.57         17.77          132.90     1326.0   \n",
       "2           M        19.69         21.25          130.00     1203.0   \n",
       "3           M        11.42         20.38           77.58      386.1   \n",
       "4           M        20.29         14.34          135.10     1297.0   \n",
       "..        ...          ...           ...             ...        ...   \n",
       "564         M        21.56         22.39          142.00     1479.0   \n",
       "565         M        20.13         28.25          131.20     1261.0   \n",
       "566         M        16.60         28.08          108.30      858.1   \n",
       "567         M        20.60         29.33          140.10     1265.0   \n",
       "568         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     mean_smoothness  mean_compactness  mean_concavity  mean_concave_points  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     mean_symmetry  mean_fractal_dimension  \n",
       "0           0.2419                 0.07871  \n",
       "1           0.1812                 0.05667  \n",
       "2           0.2069                 0.05999  \n",
       "3           0.2597                 0.09744  \n",
       "4           0.1809                 0.05883  \n",
       "..             ...                     ...  \n",
       "564         0.1726                 0.05623  \n",
       "565         0.1752                 0.05533  \n",
       "566         0.1590                 0.05648  \n",
       "567         0.2397                 0.07016  \n",
       "568         0.1587                 0.05884  \n",
       "\n",
       "[569 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clean_data\n",
    "\n",
    "original_cancer_dataset = clean_data.generate_clean_dataframe()\n",
    "original_cancer_dataset.reset_index(inplace=True)\n",
    "original_cancer_dataset.drop(\"ID\", axis=1, inplace=True)\n",
    "original_cancer_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  mean_radius  mean_texture  mean_perimeter  mean_area  \\\n",
       "0            1        17.99         10.38          122.80     1001.0   \n",
       "1            1        20.57         17.77          132.90     1326.0   \n",
       "2            1        19.69         21.25          130.00     1203.0   \n",
       "3            1        11.42         20.38           77.58      386.1   \n",
       "4            1        20.29         14.34          135.10     1297.0   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564          1        21.56         22.39          142.00     1479.0   \n",
       "565          1        20.13         28.25          131.20     1261.0   \n",
       "566          1        16.60         28.08          108.30      858.1   \n",
       "567          1        20.60         29.33          140.10     1265.0   \n",
       "568          0         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     mean_smoothness  mean_compactness  mean_concavity  mean_concave_points  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     mean_symmetry  mean_fractal_dimension  \n",
       "0           0.2419                 0.07871  \n",
       "1           0.1812                 0.05667  \n",
       "2           0.2069                 0.05999  \n",
       "3           0.2597                 0.09744  \n",
       "4           0.1809                 0.05883  \n",
       "..             ...                     ...  \n",
       "564         0.1726                 0.05623  \n",
       "565         0.1752                 0.05533  \n",
       "566         0.1590                 0.05648  \n",
       "567         0.2397                 0.07016  \n",
       "568         0.1587                 0.05884  \n",
       "\n",
       "[569 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_dataset = original_cancer_dataset.copy()\n",
    "cancer_dataset[\"diagnosis\"] = original_cancer_dataset['diagnosis'].replace([\"M\",\"B\"], [1,0])\n",
    "cancer_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3-5: Simple Linear Regression\n",
    "\n",
    "We will start with the scatter plots that we used to discuss correlation during Week 2, now through the perspective of using a Simple Linear Regression to characterize these relationships. We are going to introduce the concept of the __Coefficient of Determination__: $R^2$. \n",
    "\n",
    "$$ R^2 = 1 - \\frac{SSR}{SST} $$\n",
    "\n",
    "Where SSR is the Sum of Squares of Residual (model) and the SST is the Total Sum of Squares of the response variable. This value conceptually represents the \"amount of variance in y is explained by x\". This is a seperate concept to the Pearson Correlation Coefficient, $\\rho$, which in the cases of a __strictly linear regression__, $R^2 = \\rho^2$. \n",
    "\n",
    "Generally speaking, $R^2$ is used to characterize the fit of a model, where as $\\rho$ is used to characterize the relationship between two variables. \n",
    "\n",
    "We will perform a simple linear regression between the response variable, y, and the feature, x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ea6765ee2b450c9635ed6ca7a42deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='x', index=1, options=('diagnosis', 'mean_radius', 'mean_texture', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create scatter plots of the various features\n",
    "def calculate_correlation(x,y):\n",
    "    \"\"\"calculate pearson correlation\"\"\"\n",
    "    return calculate_mean((x - calculate_mean(x)).transpose() * (y - calculate_mean(y))) / np.sqrt(calculate_variance(x) * calculate_variance(y))\n",
    "\n",
    "def calculate_mean(x):\n",
    "    \"\"\"get the sample mean\"\"\"\n",
    "    return np.sum(x) / len(x)\n",
    "\n",
    "def calculate_variance(x):\n",
    "    \"\"\"calculate variance of the dataset\"\"\"\n",
    "    return calculate_mean((x - calculate_mean(x))**2)\n",
    "\n",
    "def simple_linear_regression(x,y, ax):\n",
    "    regression = linear_model.LinearRegression() \n",
    "    regression.fit(x.values.reshape(-1,1),y)\n",
    "    coef_of_determination = regression.score(x.values.reshape(-1,1),y)\n",
    "    x_range = np.linspace(min(x), max(x))\n",
    "    plt.plot(x_range, regression.coef_*x_range + regression.intercept_, \"--\",)\n",
    "    plt.text(1.01, 0.98, r\"$\\beta_1 = {0:.2f}$\".format(regression.coef_[0]),\n",
    "             ha='left', va='top', size =LABEL_FONT,\n",
    "             transform=ax.transAxes)\n",
    "    plt.text(1.01, 0.95, r\"$\\beta_0 = {0:.2f}$\".format(regression.intercept_),\n",
    "         ha='left', va='top', size =LABEL_FONT,\n",
    "         transform=ax.transAxes)\n",
    "    plt.text(1.01, 0.92, r\"$R^2 = {0:.2f}$\".format(coef_of_determination),\n",
    "         ha='left', va='top', size =LABEL_FONT,\n",
    "         transform=ax.transAxes)\n",
    "    \n",
    "@widgets.interact(x=list(cancer_dataset), y=list(cancer_dataset))    \n",
    "def make_scatterplot(x=\"mean_radius\",y=\"mean_area\"):\n",
    "    \"\"\"make scatterplot with correlation value and regplot\"\"\"\n",
    "    colors=[\"#e28743\", \"#1e81b0\"]\n",
    "    corr = calculate_correlation(cancer_dataset[x], cancer_dataset[y])\n",
    "    index = int(corr > 0.5)\n",
    "    plt.title(r\"correlation: $\\rho = ${:.3f}\".format(corr), color= \"grey\", size=TITLE_FONT)\n",
    "    df = cancer_dataset.reset_index()\n",
    "    ax = sns.scatterplot(data=df, x=x, y=y, alpha=0.4, hue=\"diagnosis\")\n",
    "    simple_linear_regression(cancer_dataset[x], cancer_dataset[y], ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions 6-9: Multiple Linear Regression \n",
    "\n",
    "We have other variables that we can use to explore the relationships in this dataset. We can use multiple linear regression to include more variables, where we are drawing a multi-dimensional shape, rather than simply a line, as our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56877c28453944e180be05b625d0695f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='response', index=4, options=('diagnosis', 'mean_radius', 'mean_tex…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def linear_regression(df, feature_cols, response_col, standardized = False):\n",
    "    \"\"\"\n",
    "    Use linear_model to run a linear regression using sklearn\n",
    "    \n",
    "    \"\"\"\n",
    "    X = df[feature_cols]\n",
    "    y = df[response_col]\n",
    "    if standardized:\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "        y = StandardScaler().fit_transform(y.values.reshape(-1, 1))\n",
    "    regression = linear_model.LinearRegression() \n",
    "    regression.fit(X,y)\n",
    "    \n",
    "    try:\n",
    "        print('Intercept of MLR model is {0:0.2f}'.format(regression.intercept_))\n",
    "    except TypeError:\n",
    "        print('Intercept of MLR model is {0:0.2f}'.format(regression.intercept_[0]))\n",
    "    print('Regression Coefficients: ')\n",
    "    for feature, coef in zip(feature_cols, regression.coef_.flatten()):\n",
    "        print(f'{feature} ~ {coef:.2f}')\n",
    "    return regression.predict(X), regression.score(X,y)\n",
    "\n",
    "def error_distribution(true, pred, hue=None):\n",
    "    ax = plt.subplots(figsize=(12, 8))\n",
    "    error = true-pred\n",
    "    if hue is not None: \n",
    "        sns.kdeplot(error, hue=hue, shade=True, alpha=.2)\n",
    "    else:\n",
    "        sns.kdeplot(error, shade=True, alpha=.2)\n",
    "    sns.despine()\n",
    "\n",
    "    plt.xlabel(r'Residuals ($\\epsilon$)')\n",
    "    plt.title('Error', size=TITLE_FONT)\n",
    "    plt.show()\n",
    "    \n",
    "def parity_plot(true, pred, r_squared=None, title='', hue=None):\n",
    "    \"\"\"\n",
    "    plot true vs the predicted data\n",
    "    inputs: 2 list-like (arrays) data structures\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10, 8))\n",
    "    if hue is not None:\n",
    "        sns.scatterplot(true, pred, hue=hue)\n",
    "    else: \n",
    "        sns.scatterplot(true, pred)\n",
    "    min_value = min(min(true), min(pred))\n",
    "    max_value = max(max(true), max(pred))\n",
    "    plt.plot([min_value, max_value],[min_value, max_value], '--', label=\"parity\")\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    ax.set_box_aspect(1)\n",
    "    sns.despine()\n",
    "    plt.text(1.01, 0.98, r\"$R^2 = {0:.2f}$\".format(r_squared),\n",
    "         ha='left', va='top', size =LABEL_FONT,\n",
    "         transform=ax.transAxes)\n",
    "    plt.title('Parity Plot: {}'.format(title), size=TITLE_FONT)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    error_distribution(true, pred, hue)\n",
    "\n",
    "\n",
    "def run_regression(feature_cols = \n",
    "                   ['mean_radius', \n",
    "                    'mean_texture', \n",
    "                    'mean_perimeter', \n",
    "                    'mean_smoothness', \n",
    "                    'mean_compactness', \n",
    "                    'mean_concavity', \n",
    "                    'mean_concave_points', \n",
    "                    'mean_symmetry', \n",
    "                    'mean_fractal_dimension'], \n",
    "                     response_col='mean_area',\n",
    "                     standardized=False,\n",
    "                     parity=True):\n",
    "    y_pred, r_squared = linear_regression(cancer_dataset, feature_cols, response_col, standardized = standardized)\n",
    "    if parity: parity_plot(cancer_dataset[response_col], y_pred.flatten(), r_squared, hue=cancer_dataset[\"diagnosis\"])\n",
    "\n",
    "\n",
    "@widgets.interact(response=list(cancer_dataset))   \n",
    "def regression_wrapper(response=\"mean_area\",\n",
    "                       diagnosis=False,\n",
    "                       radius=True, \n",
    "                       texture=True, \n",
    "                       perimeter=True, \n",
    "                       area=False,\n",
    "                       smoothness=True, \n",
    "                       compactness=True, \n",
    "                       concavity=True, \n",
    "                       concave_points=True, \n",
    "                       symmetry=True, \n",
    "                       fractal_dimension=True):\n",
    "    features = []\n",
    "    if diagnosis: features.append(\"diagnosis\")\n",
    "    if radius: features.append(\"mean_radius\")\n",
    "    if texture: features.append(\"mean_texture\")\n",
    "    if perimeter: features.append(\"mean_perimeter\")\n",
    "    if area: features.append(\"mean_area\")\n",
    "    if smoothness: features.append(\"mean_smoothness\")\n",
    "    if compactness: features.append(\"mean_compactness\")    \n",
    "    if concavity: features.append(\"mean_concavity\")\n",
    "    if concave_points: features.append(\"mean_concave_points\")\n",
    "    if symmetry: features.append(\"mean_symmetry\")\n",
    "    if fractal_dimension: features.append(\"mean_fractal_dimension\")\n",
    "        \n",
    "\n",
    "    run_regression(feature_cols=features, response_col = response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10: Normalization\n",
    "\n",
    "We need to be careful about how we interpret parameters in relation to each other. One method that I can use to compare coefficients is to __standardize__ the features. This will effectively shift the distribution of all of our features to have a Standard Normal ($\\mu=0,\\sigma^2=1$) distribution. We can then compare the coefficients to each other, and interpret the magnitude within the model. \n",
    "\n",
    "Note: This transformation prevents you from making a direct interpretation of the coefficient as it relates to the actual value, and is now unitless. You should interpret these as being \"model units\". This transformation also means that the y-intercept will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e104922346480a8487b32b7f2e89d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='response', index=4, options=('diagnosis', 'mean_radius', 'mean_tex…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact(response=list(cancer_dataset))   \n",
    "def regression_wrapper(response=\"mean_area\", \n",
    "                       radius=True, \n",
    "                       texture=True, \n",
    "                       perimeter=True, \n",
    "                       area=False,\n",
    "                       smoothness=True, \n",
    "                       compactness=True, \n",
    "                       concavity=True, \n",
    "                       concave_points=True, \n",
    "                       symmetry=True, \n",
    "                       fractal_dimension=True):\n",
    "    features = []\n",
    "    if radius: features.append(\"mean_radius\")\n",
    "    if texture: features.append(\"mean_texture\")\n",
    "    if perimeter: features.append(\"mean_perimeter\")\n",
    "    if area: features.append(\"mean_area\")\n",
    "    if smoothness: features.append(\"mean_smoothness\")\n",
    "    if compactness: features.append(\"mean_compactness\")    \n",
    "    if concavity: features.append(\"mean_concavity\")\n",
    "    if concave_points: features.append(\"mean_concave_points\")\n",
    "    if symmetry: features.append(\"mean_symmetry\")\n",
    "    if fractal_dimension: features.append(\"mean_fractal_dimension\")\n",
    "        \n",
    "\n",
    "    run_regression(feature_cols=features, response_col = response, standardized=True, parity=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can ignore the code below and skip to the relevant example for question 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic(x):\n",
    "    # Default - 2x^2 + 2\n",
    "    return 2*x**2 + 2\n",
    "\n",
    "def generate_noisy_data(function, noise_std, n=10, measurement_std=.2, initial_value=0, x_max=3, plot=True):\n",
    "    \"\"\"\n",
    "    This function generates noisy data with a certain amount of error applied to the function response.\n",
    "    The error is normally distributed around the noise_std.\n",
    "    \"\"\"\n",
    "    x = np.linspace(0, x_max, n) \n",
    "    x_noise = np.random.normal(0, measurement_std, len(x))\n",
    "    x += x_noise\n",
    "    y_noise = np.random.normal(0, noise_std, len(x))\n",
    "    y = function(x) + initial_value\n",
    "    y += y_noise\n",
    "    if plot:\n",
    "        plt.plot(x, y, 'C0.', label='data')\n",
    "        x_func = np.linspace(0, max(x)+measurement_std)\n",
    "        y_func = function(x_func) + initial_value\n",
    "        plt.plot(x_func, y_func, 'C0--', label='function')\n",
    "        plt.fill_between(x_func, y_func+noise_std, y_func-noise_std,\n",
    "                         alpha=0.1)          # Transparency of the fill\n",
    "        plt.title(r'$ y = 2x^2 + 2$ with noise (std of {})'.format(noise_std))\n",
    "        plt.legend(loc='best')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.xlim(0, max(x)+measurement_std)\n",
    "        plt.show()\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def plot_model(x, y, x_model, y_model, title = '',r_squared=None, x_test=None, y_test=None):\n",
    "    \"\"\"\n",
    "    Plotter function.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.plot(x,y, 'o', label='data')\n",
    "    if x_test is not None: plt.plot(x_test,y_test,\"o\", label='test')\n",
    "    plt.plot(x_model, y_model, '--', label='model')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.xlim(0, max(x))\n",
    "    plt.title(title)\n",
    "    plt.text(1.01, 0.98, r\"$R^2 = {0:.2f}$\".format(r_squared),\n",
    "         ha='left', va='top', size =LABEL_FONT,\n",
    "         transform=plt.gca().transAxes)    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def polynomial_feature_example(x, y, degrees=6, x_test=None, y_test=None):\n",
    "    \"\"\"\n",
    "    Perform regularization on a polynomial feature set. \n",
    "    \"\"\"\n",
    "    poly_transform = PolynomialFeatures(degree=degrees, include_bias = False)\n",
    "    x_poly = poly_transform.fit_transform(x.reshape(-1,1))\n",
    "    \n",
    "    #Regularization techniques need to be scaled in order to work properly\n",
    "    x_scaler = StandardScaler().fit(x_poly)\n",
    "    y_scaler = StandardScaler().fit(y.reshape(-1,1))\n",
    "    x_poly_z = x_scaler.transform(x_poly)\n",
    "    y_z = y_scaler.transform(y.reshape(-1,1))\n",
    "    \n",
    "    #Code to perform the model fitting and parameter estimation\n",
    "    #Least Squares problem\n",
    "    plt.suptitle('Linear Regression', fontsize=20, fontweight='bold')\n",
    "    lm_poly = linear_model.LinearRegression(fit_intercept=True)\n",
    "    lm_poly.fit(x_poly_z,y_z)\n",
    "\n",
    "    x_model = np.linspace(min(x), max(x), 150).reshape(-1,1)\n",
    "    x_model_transform = poly_transform.fit_transform(x_model)\n",
    "    x_model_transform_z = x_scaler.transform(x_model_transform)\n",
    "    \n",
    "    \n",
    "    y_model = lm_poly.predict(x_model_transform_z)*y_scaler.scale_ + y_scaler.mean_\n",
    "    \n",
    "    #********************************************************************************\n",
    "    # Coefficients from scaled model can be transformed back into original units\n",
    "    # This code is outside the scope of this class and can be ignored. \n",
    "    \n",
    "    unscaled_coefficients = (lm_poly.coef_ * y_scaler.scale_ / x_scaler.scale_).flatten()\n",
    "    \n",
    "    poly_terms = [r'$({0:.3f})x ^ {{{1}}}$'.format(coef, i+1) for i, coef in enumerate(unscaled_coefficients)\n",
    "                 if coef != 0]\n",
    "    \n",
    "    unscaled_intercept = lm_poly.intercept_*y_scaler.scale_ + y_scaler.mean_ \\\n",
    "                            - sum(unscaled_coefficients*x_scaler.mean_)\n",
    "        \n",
    "    intercept_str = r'${0:.1f} + $'.format(unscaled_intercept[0])\n",
    "    title =  intercept_str + r'$+$'.join(poly_terms)\n",
    "    #********************************************************************************\n",
    "    r_squared = lm_poly.score(x_poly_z,y_z)\n",
    "    ax = plot_model(x, y, x_model, y_model, title=title, r_squared = r_squared, x_test=x_test, y_test=y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions 11-12: Underdefined and Overdefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89859fd6ef424a83a6449842efc31281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='n'), IntSlider(value=7, description='degrees', max=12),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact_manual(n=(0,100), degrees=(0,12))\n",
    "def run_polynomial_experiment(n=20, degrees=7):\n",
    "    x_data, y_data = generate_noisy_data(quadratic, 2, n)\n",
    "    polynomial_feature_example(x_data, y_data, degrees=degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 13: Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ffa3cc7340453b8fffe63877743f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='n'), IntSlider(value=7, description='degrees', max=12),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact_manual(n=(0,100), degrees=(0,12))\n",
    "def run_polynomial_experiment(n=20, degrees=7):\n",
    "    x_data, y_data = generate_noisy_data(quadratic, 2, n)\n",
    "    x_test, y_test = generate_noisy_data(quadratic, 2, 50, plot=False)\n",
    "    polynomial_feature_example(x_data, y_data, degrees=degrees, x_test=x_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
